{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 573 - Feature and Model Selection\n",
    "\n",
    "# Lab 4: A mini project - Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "0. [Submission instructions](#si) (4%)\n",
    "1. [Understanding the problem](#1) (4%)\n",
    "2. [Data splitting](#2) (2%)\n",
    "3. [EDA](#3) (10%)\n",
    "4. (Optional) [Feature engineering](#4)\n",
    "5. [Preprocessing and transformations](#5) (10%)\n",
    "6. [Baseline model](#6) (2%)\n",
    "7. [Linear models](#7) (10%)\n",
    "8. [Different models](#8) (16%)\n",
    "9. (Optional) [Feature selection](#9)\n",
    "10. [Hyperparameter optimization](#10) (10%)\n",
    "11. [Interpretation and feature importances](#11) (10%)\n",
    "12. [Results on the test set](#12) (10%)\n",
    "13. [Summary of the results](#13) (12%)\n",
    "15. (Optional) [Reproducible data analysis pipeline](#14)\n",
    "15. (Optional) [Your takeaway from the course](#15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "rubric={mechanics:4}\n",
    "\n",
    "You will receive marks for correctly submitting this assignment. To submit this assignment, follow the instructions below:\n",
    "\n",
    "- **Which problem did you pick, classification or regression?**\n",
    "- **Report your test score here along with the metric used:** \n",
    "- **Please add a link to your GitHub repository here: https://github.ubc.ca/mds-2021-22/DSCI_573_lab4_mrezam**\n",
    "- **You don't have to but you may work on this assignment in a group (group size <= 4) and submit your assignment as a group.** \n",
    "- Below are some instructions on working as a group.  \n",
    "    - The maximum group size is 4. \n",
    "    - You can choose your own group members. Since I don't know your groups in advance, I am not opening this lab as a group lab. So you all will have a separate GitHub repository for your labs and you'll have to decide how you want to collaborate. \n",
    "    - Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "    - Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "    - It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. [Here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members) are some instructions on adding group members in Gradescope.  \n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).\n",
    "- Make at least three commits in your lab's GitHub repository.\n",
    "- Push the final .ipynb file with your solutions to your GitHub repository for this lab.\n",
    "- Upload the .ipynb file to Gradescope.\n",
    "- If the .ipynb file is too big or doesn't render on Gradescope for some reason, also upload a pdf or html in addition to the .ipynb. \n",
    "- Make sure that your plots/output are rendered properly in Gradescope.\n",
    "\n",
    "> [Here](https://github.com/UBC-MDS/public/tree/master/rubric) you will find the description of each rubric used in MDS.\n",
    "\n",
    "> As usual, do not push the data to the repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('data_server')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.linalg as npla\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn import datasets\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, RidgeCV\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "import altair as alt\n",
    "# Save a vega-lite spec and a PNG blob for each plot in the notebook\n",
    "alt.renderers.enable('mimetype')\n",
    "# Handle large data sets without embedding them in the notebook\n",
    "alt.data_transformers.enable('data_server')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "\n",
    "In this lab you will be working on an open-ended mini-project, where you will put all the different things you have learned so far in 571 and 573 together to solve an interesting problem.\n",
    "\n",
    "A few notes and tips when you work on this mini-project: \n",
    "\n",
    "#### Tips\n",
    "1. This mini-project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). Make sure you explain your decisions whenever necessary. \n",
    "2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n",
    "3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n",
    "\n",
    "#### Assessment\n",
    "We plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n",
    "\n",
    "\n",
    "#### A final note\n",
    "Finally, this style of this \"project\" question is different from other assignments. It'll be up to you to decide when you're \"done\" -- in fact, this is one of the hardest parts of real projects. But please don't spend WAY too much time on this... perhaps \"a few hours\" (2-8 hours???) is a good guideline for a typical submission. Of course if you're having fun you're welcome to spend as much time as you want! But, if so, try not to do it out of perfectionism or getting the best possible grade. Do it because you're learning and enjoying it. Students from the past cohorts have found such kind of labs useful and fun and I hope you enjoy it as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pick your problem and explain what exactly you are trying to predict <a name=\"1\"></a>\n",
    "<hr>\n",
    "rubric={reasoning:4}\n",
    "\n",
    "In this mini project, you will pick one of the following problems: \n",
    "\n",
    "- A classification problem of predicting whether a credit card client will default or not. For this problem, you will use [Default of Credit Card Clients Dataset](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). In this data set, there are 30,000 examples and 24 features, and the goal is to estimate whether a person will default (fail to pay) their credit card bills; this column is labeled \"default.payment.next.month\" in the data. The rest of the columns can be used as features. You may take some ideas and compare your results with [the associated research paper](https://www.sciencedirect.com/science/article/pii/S0957417407006719), which is available through [the UBC library](https://www.library.ubc.ca/). \n",
    "\n",
    "OR \n",
    "\n",
    "- A regression problem of predicting `reviews_per_month`, as a proxy for the popularity of the listing with [New York City Airbnb listings from 2019 dataset](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data). Airbnb could use this sort of model to predict how popular future listings might be before they are posted, perhaps to help guide hosts create more appealing listings. In reality they might instead use something like vacancy rate or average rating as their target, but we do not have that available here.\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Spend some time understanding the problem and what each feature means. Write a few sentences on your initial thoughts on the problem and the dataset. \n",
    "2. Download the dataset and read it as a pandas dataframe. \n",
    "3. Carry out any preliminary preprocessing, if needed (e.g., changing feature names, handling of NaN values etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data splitting <a name=\"2\"></a>\n",
    "<hr>\n",
    "rubric={reasoning:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train and test portions.\n",
    "\n",
    "> Make decision on the `test_size` based on the capacity of your laptop. Don't forget to use a random state.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df = pd.read_csv('AB_NYC_2019.csv')\n",
    "train_df, test_df = train_test_split(airbnb_df, test_size=0.4, random_state=123)\n",
    "\n",
    "# We have split the X and Y in the preprocessing step after w ehave cleaned the data in the EDA step\n",
    "\n",
    "# X_train, y_train = train_df.drop(columns=['reviews_per_month']) , train_df['reviews_per_month']    \n",
    "# X_test, y_test = test_df.drop(columns = ['reviews_per_month']) , test_df['reviews_per_month']\n",
    "\n",
    "# train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA <a name=\"3\"></a>\n",
    "<hr>\n",
    "rubric={viz:4,reasoning:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Perform exploratory data analysis on the train set.\n",
    "2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Summarize your initial observations about the data. \n",
    "4. Pick appropriate metric/metrics for assessment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.933700e+04</td>\n",
       "      <td>2.933700e+04</td>\n",
       "      <td>29337.000000</td>\n",
       "      <td>29337.000000</td>\n",
       "      <td>29337.000000</td>\n",
       "      <td>29337.000000</td>\n",
       "      <td>29337.000000</td>\n",
       "      <td>23386.000000</td>\n",
       "      <td>29337.000000</td>\n",
       "      <td>29337.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.891988e+07</td>\n",
       "      <td>6.714579e+07</td>\n",
       "      <td>40.729013</td>\n",
       "      <td>-73.952217</td>\n",
       "      <td>150.939121</td>\n",
       "      <td>7.141971</td>\n",
       "      <td>23.354501</td>\n",
       "      <td>1.369867</td>\n",
       "      <td>7.003340</td>\n",
       "      <td>112.803627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.102155e+07</td>\n",
       "      <td>7.835404e+07</td>\n",
       "      <td>0.054594</td>\n",
       "      <td>0.046091</td>\n",
       "      <td>228.224188</td>\n",
       "      <td>22.272110</td>\n",
       "      <td>44.692480</td>\n",
       "      <td>1.706732</td>\n",
       "      <td>32.511623</td>\n",
       "      <td>131.544488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.539000e+03</td>\n",
       "      <td>2.438000e+03</td>\n",
       "      <td>40.506410</td>\n",
       "      <td>-74.244420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.350729e+06</td>\n",
       "      <td>7.740184e+06</td>\n",
       "      <td>40.690090</td>\n",
       "      <td>-73.983030</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.951751e+07</td>\n",
       "      <td>3.071907e+07</td>\n",
       "      <td>40.723140</td>\n",
       "      <td>-73.955530</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.916531e+07</td>\n",
       "      <td>1.064429e+08</td>\n",
       "      <td>40.763280</td>\n",
       "      <td>-73.936430</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>227.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.648561e+07</td>\n",
       "      <td>2.743213e+08</td>\n",
       "      <td>40.912340</td>\n",
       "      <td>-73.712990</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>365.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       host_id      latitude     longitude         price  \\\n",
       "count  2.933700e+04  2.933700e+04  29337.000000  29337.000000  29337.000000   \n",
       "mean   1.891988e+07  6.714579e+07     40.729013    -73.952217    150.939121   \n",
       "std    1.102155e+07  7.835404e+07      0.054594      0.046091    228.224188   \n",
       "min    2.539000e+03  2.438000e+03     40.506410    -74.244420      0.000000   \n",
       "25%    9.350729e+06  7.740184e+06     40.690090    -73.983030     69.000000   \n",
       "50%    1.951751e+07  3.071907e+07     40.723140    -73.955530    107.000000   \n",
       "75%    2.916531e+07  1.064429e+08     40.763280    -73.936430    175.000000   \n",
       "max    3.648561e+07  2.743213e+08     40.912340    -73.712990  10000.000000   \n",
       "\n",
       "       minimum_nights  number_of_reviews  reviews_per_month  \\\n",
       "count    29337.000000       29337.000000       23386.000000   \n",
       "mean         7.141971          23.354501           1.369867   \n",
       "std         22.272110          44.692480           1.706732   \n",
       "min          1.000000           0.000000           0.010000   \n",
       "25%          1.000000           1.000000           0.190000   \n",
       "50%          3.000000           5.000000           0.710000   \n",
       "75%          5.000000          23.000000           2.010000   \n",
       "max       1250.000000         629.000000          58.500000   \n",
       "\n",
       "       calculated_host_listings_count  availability_365  \n",
       "count                    29337.000000      29337.000000  \n",
       "mean                         7.003340        112.803627  \n",
       "std                         32.511623        131.544488  \n",
       "min                          1.000000          0.000000  \n",
       "25%                          1.000000          0.000000  \n",
       "50%                          1.000000         45.000000  \n",
       "75%                          2.000000        227.000000  \n",
       "max                        327.000000        365.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29337 entries, 17877 to 15725\n",
      "Data columns (total 16 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              29337 non-null  int64  \n",
      " 1   name                            29328 non-null  object \n",
      " 2   host_id                         29337 non-null  int64  \n",
      " 3   host_name                       29325 non-null  object \n",
      " 4   neighbourhood_group             29337 non-null  object \n",
      " 5   neighbourhood                   29337 non-null  object \n",
      " 6   latitude                        29337 non-null  float64\n",
      " 7   longitude                       29337 non-null  float64\n",
      " 8   room_type                       29337 non-null  object \n",
      " 9   price                           29337 non-null  int64  \n",
      " 10  minimum_nights                  29337 non-null  int64  \n",
      " 11  number_of_reviews               29337 non-null  int64  \n",
      " 12  last_review                     23386 non-null  object \n",
      " 13  reviews_per_month               23386 non-null  float64\n",
      " 14  calculated_host_listings_count  29337 non-null  int64  \n",
      " 15  availability_365                29337 non-null  int64  \n",
      "dtypes: float64(3), int64(7), object(6)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 17877      1683437\n",
       "14638     10307134\n",
       "7479        329917\n",
       "47058     35965489\n",
       "9769      29156329\n",
       "           ...    \n",
       "7763       4291007\n",
       "15377     66501870\n",
       "17730      7177483\n",
       "28030    159769278\n",
       "15725     65809485\n",
       "Name: host_id, Length: 29337, dtype: int64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['host_id'].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 17877    2018-05-28\n",
       "14638    2019-06-16\n",
       "7479     2016-10-21\n",
       "47058           NaN\n",
       "9769     2018-09-19\n",
       "            ...    \n",
       "7763     2019-06-01\n",
       "15377    2019-06-30\n",
       "17730    2019-01-01\n",
       "28030    2019-06-04\n",
       "15725    2019-04-29\n",
       "Name: last_review, Length: 29337, dtype: object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['last_review'].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'host_id', 'host_name', 'neighbourhood_group',\n",
       "       'neighbourhood', 'latitude', 'longitude', 'room_type', 'price',\n",
       "       'minimum_nights', 'number_of_reviews', 'last_review',\n",
       "       'reviews_per_month', 'calculated_host_listings_count',\n",
       "       'availability_365'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number rows that have missing data in reviews per month and 0 number of reviews (5951, 16)\n",
      "The number rows that have 0 number of reviews (5951, 16)\n"
     ]
    }
   ],
   "source": [
    "print('The number rows that have missing data in reviews per month and 0 number of reviews', train_df.query('reviews_per_month.isna() & number_of_reviews==0').shape)\n",
    "\n",
    "print('The number rows that have 0 number of reviews', train_df.query('number_of_reviews==0').shape)\n",
    "\n",
    "# Exactly the data that their review per month are missing have 0 the number of reviews. Therefore, we can give zero to these missing data .\n",
    "\n",
    "train_df.loc[train_df['reviews_per_month'].isna(), 'reviews_per_month'] = 0\n",
    "\n",
    "test_df.loc[test_df['reviews_per_month'].isna(), 'reviews_per_month'] = 0\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v4+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v4.8.1.json",
       "config": {
        "view": {
         "continuousHeight": 300,
         "continuousWidth": 400
        }
       },
       "data": {
        "url": "http://localhost:20352/aea1deda92b3beb6feb98166393f1659.json"
       },
       "encoding": {
        "color": {
         "field": "corr",
         "scale": {
          "domain": [
           -1,
           1
          ],
          "scheme": "blueorange"
         },
         "type": "quantitative"
        },
        "size": {
         "field": "corr",
         "type": "quantitative"
        },
        "x": {
         "field": "level_0",
         "type": "nominal"
        },
        "y": {
         "field": "level_1",
         "type": "nominal"
        }
       },
       "mark": "circle"
      },
      "text/plain": [
       "<VegaLite 4 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df = train_df.select_dtypes('number').corr('spearman').abs().stack().reset_index(name='corr')\n",
    "corr_df.loc[corr_df['corr'] == 1, 'corr'] = 0  # Remove diagonal\n",
    "corr_df\n",
    "alt.Chart(corr_df).mark_circle().encode(\n",
    "    x='level_0',\n",
    "    y='level_1',\n",
    "    size='corr',\n",
    "    color=alt.Color('corr', scale=alt.Scale(scheme='blueorange', domain=(-1, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v4+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v4.8.1.json",
       "columns": 3,
       "config": {
        "view": {
         "continuousHeight": 300,
         "continuousWidth": 400
        }
       },
       "repeat": [
        "latitude",
        "longitude",
        "price",
        "minimum_nights",
        "number_of_reviews",
        "reviews_per_month",
        "calculated_host_listings_count",
        "availability_365"
       ],
       "spec": {
        "data": {
         "url": "http://localhost:20352/3a2a037398c656208a70e57ede14c06c.json"
        },
        "encoding": {
         "x": {
          "bin": {
           "maxbins": 40
          },
          "field": {
           "repeat": "repeat"
          },
          "type": "quantitative"
         },
         "y": {
          "aggregate": "count",
          "type": "quantitative"
         }
        },
        "height": 200,
        "mark": "bar",
        "width": 300
       }
      },
      "text/plain": [
       "<VegaLite 4 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "alt.Chart(train_df).mark_bar().encode(\n",
    "     alt.X(alt.repeat(), type='quantitative', bin=alt.Bin(maxbins=40)),\n",
    "     y='count()',\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=200\n",
    ").repeat(\n",
    "    ['latitude', 'longitude', 'price', 'minimum_nights', 'number_of_reviews', \n",
    "    'reviews_per_month', 'calculated_host_listings_count','availability_365'],\n",
    "    columns=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Entire home/apt', 'Private room', 'Shared room'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"room_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bedford-Stuyvesant    1899\n",
       "Williamsburg          1873\n",
       "Harlem                1316\n",
       "Bushwick              1163\n",
       "Hell's Kitchen         932\n",
       "                      ... \n",
       "Huguenot                 1\n",
       "Rosebank                 1\n",
       "Richmondtown             1\n",
       "Holliswood               1\n",
       "Eltingville              1\n",
       "Name: neighbourhood, Length: 214, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"neighbourhood\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 4. Feature engineering <a name=\"4\"></a>\n",
    "<hr>\n",
    "rubric={reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out feature engineering. In other words, extract new features relevant for the problem and work with your new feature set in the following exercises. You may have to go back and forth between feature engineering and preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing and transformations <a name=\"5\"></a>\n",
    "<hr>\n",
    "rubric={accuracy:6,reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different feature types and the transformations you would apply on each feature type. \n",
    "2. Define a column transformer, if necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(columns=['reviews_per_month']) , train_df['reviews_per_month']    \n",
    "X_test, y_test = test_df.drop(columns = ['reviews_per_month']) , test_df['reviews_per_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_feats = ['latitude','longitude','price','minimum_nights','number_of_reviews','calculated_host_listings_count','availability_365']\n",
    "categorical_feats = ['neighbourhood_group', 'neighbourhood', 'room_type']\n",
    "drop_feats = ['id','host_id', 'host_name', 'last_review']\n",
    "text_feats = \"name\"\n",
    "\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_feats),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), categorical_feats),\n",
    "    (CountVectorizer(stop_words=\"english\"), text_feats),\n",
    "    (\"drop\", drop_feats),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Baseline model <a name=\"6\"></a>\n",
    "<hr>\n",
    "rubric={accuracy:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try `scikit-learn`'s baseline model and report results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.001 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>-0.001 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          dummy\n",
       "fit_time      0.005 (+/- 0.001)\n",
       "score_time    0.001 (+/- 0.001)\n",
       "test_score   -0.001 (+/- 0.001)\n",
       "train_score   0.000 (+/- 0.000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyRegressor()\n",
    "results['dummy'] = mean_std_cross_val_scores(dummy, X_train, y_train, cv=10, return_train_score=True)\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Linear models <a name=\"7\"></a>\n",
    "<hr>\n",
    "rubric={accuracy:6,reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try a linear model as a first real attempt. \n",
    "2. Carry out hyperparameter tuning to explore different values for the regularization hyperparameter. \n",
    "3. Report cross-validation scores along with standard deviation. \n",
    "4. Summarize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>Ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "      <td>0.354 (+/- 0.113)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.001 (+/- 0.001)</td>\n",
       "      <td>0.045 (+/- 0.005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>-0.001 (+/- 0.001)</td>\n",
       "      <td>0.350 (+/- 0.028)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.525 (+/- 0.009)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          dummy              Ridge\n",
       "fit_time      0.005 (+/- 0.001)  0.354 (+/- 0.113)\n",
       "score_time    0.001 (+/- 0.001)  0.045 (+/- 0.005)\n",
       "test_score   -0.001 (+/- 0.001)  0.350 (+/- 0.028)\n",
       "train_score   0.000 (+/- 0.000)  0.525 (+/- 0.009)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_ridge = make_pipeline(preprocessor, Ridge())\n",
    "results['Ridge'] = mean_std_cross_val_scores(pipe_ridge, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37466322891747433"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid_alpha = {\n",
    "    \"ridge__alpha\": 10.0 ** np.arange(-2, 6, 1), \n",
    "}\n",
    "\n",
    "rs_alpha = RandomizedSearchCV(\n",
    "    pipe_ridge,\n",
    "    param_distributions=param_grid_alpha,\n",
    "    n_jobs=-1,\n",
    "    n_iter=6,\n",
    "    cv=5,\n",
    "    random_state=123,\n",
    ")\n",
    "rs_alpha.fit(X_train, y_train)\n",
    "rs_alpha.best_params_\n",
    "rs_alpha.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Different models <a name=\"8\"></a>\n",
    "<hr>\n",
    "rubric={accuracy:10,reasoning:6}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try at least 3 other models aside from a linear model. \n",
    "2. Summarize your results in terms of overfitting/underfitting and fit and score times. Can you beat a linear model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "      <td>0.354 (+/- 0.113)</td>\n",
       "      <td>1.438 (+/- 0.102)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.001 (+/- 0.001)</td>\n",
       "      <td>0.045 (+/- 0.005)</td>\n",
       "      <td>0.091 (+/- 0.004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>-0.001 (+/- 0.001)</td>\n",
       "      <td>0.350 (+/- 0.028)</td>\n",
       "      <td>0.542 (+/- 0.040)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.525 (+/- 0.009)</td>\n",
       "      <td>0.662 (+/- 0.009)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          dummy              Ridge               LGBM\n",
       "fit_time      0.005 (+/- 0.001)  0.354 (+/- 0.113)  1.438 (+/- 0.102)\n",
       "score_time    0.001 (+/- 0.001)  0.045 (+/- 0.005)  0.091 (+/- 0.004)\n",
       "test_score   -0.001 (+/- 0.001)  0.350 (+/- 0.028)  0.542 (+/- 0.040)\n",
       "train_score   0.000 (+/- 0.000)  0.525 (+/- 0.009)  0.662 (+/- 0.009)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "\n",
    "pipe_lgbm = make_pipeline(preprocessor, LGBMRegressor(random_state=123))\n",
    "results['LGBM'] = mean_std_cross_val_scores(pipe_lgbm, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>LGBM</th>\n",
       "      <th>XGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "      <td>0.354 (+/- 0.113)</td>\n",
       "      <td>1.438 (+/- 0.102)</td>\n",
       "      <td>3.418 (+/- 0.627)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.001 (+/- 0.001)</td>\n",
       "      <td>0.045 (+/- 0.005)</td>\n",
       "      <td>0.091 (+/- 0.004)</td>\n",
       "      <td>0.100 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>-0.001 (+/- 0.001)</td>\n",
       "      <td>0.350 (+/- 0.028)</td>\n",
       "      <td>0.542 (+/- 0.040)</td>\n",
       "      <td>0.535 (+/- 0.039)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.525 (+/- 0.009)</td>\n",
       "      <td>0.662 (+/- 0.009)</td>\n",
       "      <td>0.727 (+/- 0.008)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          dummy              Ridge               LGBM  \\\n",
       "fit_time      0.005 (+/- 0.001)  0.354 (+/- 0.113)  1.438 (+/- 0.102)   \n",
       "score_time    0.001 (+/- 0.001)  0.045 (+/- 0.005)  0.091 (+/- 0.004)   \n",
       "test_score   -0.001 (+/- 0.001)  0.350 (+/- 0.028)  0.542 (+/- 0.040)   \n",
       "train_score   0.000 (+/- 0.000)  0.525 (+/- 0.009)  0.662 (+/- 0.009)   \n",
       "\n",
       "                           XGB  \n",
       "fit_time     3.418 (+/- 0.627)  \n",
       "score_time   0.100 (+/- 0.003)  \n",
       "test_score   0.535 (+/- 0.039)  \n",
       "train_score  0.727 (+/- 0.008)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_xgb = make_pipeline(preprocessor, XGBRegressor(verbosity=0))\n",
    "results['XGB'] = mean_std_cross_val_scores(pipe_xgb, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>LGBM</th>\n",
       "      <th>XGB</th>\n",
       "      <th>Catboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "      <td>0.354 (+/- 0.113)</td>\n",
       "      <td>1.438 (+/- 0.102)</td>\n",
       "      <td>3.418 (+/- 0.627)</td>\n",
       "      <td>14.497 (+/- 3.271)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.001 (+/- 0.001)</td>\n",
       "      <td>0.045 (+/- 0.005)</td>\n",
       "      <td>0.091 (+/- 0.004)</td>\n",
       "      <td>0.100 (+/- 0.003)</td>\n",
       "      <td>0.061 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>-0.001 (+/- 0.001)</td>\n",
       "      <td>0.350 (+/- 0.028)</td>\n",
       "      <td>0.542 (+/- 0.040)</td>\n",
       "      <td>0.535 (+/- 0.039)</td>\n",
       "      <td>0.545 (+/- 0.026)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.525 (+/- 0.009)</td>\n",
       "      <td>0.662 (+/- 0.009)</td>\n",
       "      <td>0.727 (+/- 0.008)</td>\n",
       "      <td>0.677 (+/- 0.008)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          dummy              Ridge               LGBM  \\\n",
       "fit_time      0.005 (+/- 0.001)  0.354 (+/- 0.113)  1.438 (+/- 0.102)   \n",
       "score_time    0.001 (+/- 0.001)  0.045 (+/- 0.005)  0.091 (+/- 0.004)   \n",
       "test_score   -0.001 (+/- 0.001)  0.350 (+/- 0.028)  0.542 (+/- 0.040)   \n",
       "train_score   0.000 (+/- 0.000)  0.525 (+/- 0.009)  0.662 (+/- 0.009)   \n",
       "\n",
       "                           XGB            Catboost  \n",
       "fit_time     3.418 (+/- 0.627)  14.497 (+/- 3.271)  \n",
       "score_time   0.100 (+/- 0.003)   0.061 (+/- 0.007)  \n",
       "test_score   0.535 (+/- 0.039)   0.545 (+/- 0.026)  \n",
       "train_score  0.727 (+/- 0.008)   0.677 (+/- 0.008)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cb = make_pipeline(preprocessor, CatBoostRegressor(verbose=0))\n",
    "results['Catboost'] = mean_std_cross_val_scores(pipe_cb, X_train, y_train, return_train_score=True)\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 9. Feature selection <a name=\"9\"></a>\n",
    "<hr>\n",
    "rubric={reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to select relevant features. You may try `RFECV`, forward selection or L1 regularization for this. Do the results improve with feature selection? Summarize your results. If you see improvements in the results, keep feature selection in your pipeline. If not, you may abandon it in the next exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Hyperparameter optimization <a name=\"10\"></a>\n",
    "<hr>\n",
    "rubric={accuracy:6,reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgbm = {\n",
    "    \"lgbmregressor__num_leaves\": [10,30,50,100], \n",
    "    \"lgbmregressor__max_depth\": [-1, 1000, 5000, 10000, 30000], \n",
    "    \"lgbmregressor__n_estimators\": 10 ** np.arange(1, 6, 1)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe_lgbm,\n",
    "    param_distributions=param_grid_lgbm,\n",
    "    n_jobs=-1,\n",
    "    n_iter=6,\n",
    "    cv=5,\n",
    "    random_state=123,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               ['latitude',\n",
       "                                                                                'longitude',\n",
       "                                                                                'price',\n",
       "                                                                                'minimum_nights',\n",
       "                                                                                'number_of_reviews',\n",
       "                                                                                'calculated_host_listings_count',\n",
       "                                                                                'availability_365']),\n",
       "                                                                              ('onehotencoder',\n",
       "                                                                               OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                               ['neighbourhood_group',\n",
       "                                                                                'neighbour...\n",
       "                                                                               CountVectorizer(stop_words='english'),\n",
       "                                                                               'name'),\n",
       "                                                                              ('drop',\n",
       "                                                                               'drop',\n",
       "                                                                               ['id',\n",
       "                                                                                'host_id',\n",
       "                                                                                'host_name',\n",
       "                                                                                'last_review'])])),\n",
       "                                             ('lgbmregressor',\n",
       "                                              LGBMRegressor(random_state=123))]),\n",
       "                   n_iter=6, n_jobs=-1,\n",
       "                   param_distributions={'lgbmregressor__max_depth': [-1, 1000,\n",
       "                                                                     5000,\n",
       "                                                                     10000,\n",
       "                                                                     30000],\n",
       "                                        'lgbmregressor__n_estimators': array([    10,    100,   1000,  10000, 100000]),\n",
       "                                        'lgbmregressor__num_leaves': [10, 30,\n",
       "                                                                      50,\n",
       "                                                                      100]},\n",
       "                   random_state=123)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5447291434721689"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgbmregressor__num_leaves': 10,\n",
       " 'lgbmregressor__n_estimators': 1000,\n",
       " 'lgbmregressor__max_depth': -1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Interpretation and feature importances <a name=\"1\"></a>\n",
    "<hr>\n",
    "rubric={accuracy:6,reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Use the methods we saw in class (e.g., `eli5`, `shap`), or any other methods of your choice, to examine the most important features of one of the non-linear models. \n",
    "2. Summarize your observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Results on the test set <a name=\"12\"></a>\n",
    "<hr>\n",
    "\n",
    "rubric={accuracy:6,reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try your best performing model on the test data and report test scores. \n",
    "2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias? \n",
    "3. Take one or two test predictions and explain them with SHAP force plots.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5677886476112927"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary of results <a name=\"13\"></a>\n",
    "<hr>\n",
    "rubric={reasoning:12}\n",
    "\n",
    "Imagine that you want to present the summary of these results to your boss and co-workers. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a table summarizing important results. \n",
    "2. Write concluding remarks.\n",
    "3. Discuss other ideas that you did not try but could potentially improve the performance/interpretability . \n",
    "3. Report your final test score along with the metric you used at the top of this notebook in the [Submission instructions section](#si)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 14. Creating a data analysis pipeline <a name=\"14\"></a>\n",
    "rubric={reasoning:2}\n",
    "\n",
    "**Your tasks:**\n",
    "- In 522 you learned how build a reproducible data analysis pipeline. Convert this notebook into scripts and create a reproducible data analysis pipeline with appropriate documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 15. Your takeaway from the course <a name=\"15\"></a>\n",
    "<hr>\n",
    "rubric={reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "What is your biggest takeaway from this course? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLEASE READ BEFORE YOU SUBMIT:** \n",
    "\n",
    "When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from \"1\" will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Push all your work to your GitHub lab repository. \n",
    "4. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. \n",
    "5. Make sure that the plots and output are rendered properly in your submitted file. If the .ipynb file is too big and doesn't render on Gradescope, also upload a pdf or html in addition to the .ipynb so that the TAs can view your submission on Gradescope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done!! Have a great weekend! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"eva-well-done.png\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59ec1b06cbe0f59b0ed94fc4092fe2d54848c1822f2af32b696a7e1aa62c963f"
  },
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
